{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9532e826-0187-46a7-9cd8-47216ec12e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import ollama\n",
    "import re\n",
    "\n",
    "def get_timestamp():\n",
    "    \"\"\"\n",
    "    Returns the current timestamp in the format YYYYMMDD_HHMMSS.\n",
    "    \"\"\"\n",
    "    return time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "def create_output_folder(model_name):\n",
    "    \"\"\"\n",
    "    Creates a timestamped output folder for a given model name.\n",
    "    Replaces forbidden characters in the folder name.\n",
    "    \"\"\"\n",
    "    # Create the base output and tagging folders\n",
    "    base_output_path = os.path.join(\"voiceapp\", \"output\")\n",
    "    tagging_folder_path = os.path.join(base_output_path, \"tagging_folder\")\n",
    "    \n",
    "    os.makedirs(base_output_path, exist_ok=True)\n",
    "    os.makedirs(tagging_folder_path, exist_ok=True)\n",
    "\n",
    "    # Sanitize the model name by replacing forbidden characters with '_'\n",
    "    safe_model_name = re.sub(r'[<>:\"/\\\\|?*]', '_', model_name)\n",
    "\n",
    "    # Generate a timestamp and create the final folder name\n",
    "    timestamp = get_timestamp()\n",
    "    folder_name = f\"{safe_model_name}_{timestamp}\"\n",
    "\n",
    "    # Create the model-specific folder\n",
    "    model_folder_path = os.path.join(tagging_folder_path, folder_name)\n",
    "    os.makedirs(model_folder_path, exist_ok=True)\n",
    "\n",
    "    return model_folder_path\n",
    "\n",
    "def initialize_environment(models_list):\n",
    "    \"\"\"\n",
    "    Initializes the environment by creating output folders for each model\n",
    "    and loading the tokenizer and embedding model.\n",
    "    \"\"\"\n",
    "    output_folders = {}\n",
    "\n",
    "    for model_name in models_list:\n",
    "        output_folders[model_name] = create_output_folder(model_name)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-distilroberta-v1\")\n",
    "    model = AutoModel.from_pretrained(\"sentence-transformers/all-distilroberta-v1\")\n",
    "\n",
    "    return output_folders, tokenizer, model\n",
    "\n",
    "\n",
    "def read_file_paths(input_file):\n",
    "    \"\"\"\n",
    "    Reads file paths from the input file.\n",
    "    \"\"\"\n",
    "    with open(input_file, 'r') as f:\n",
    "        file_paths = [line.strip().replace('.mp3', '.txt') for line in f]\n",
    "    return file_paths\n",
    "\n",
    "def split_into_chunks(text, chunk_size=100):\n",
    "    \"\"\"\n",
    "    Splits a text into chunks of approximately 100 words.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    return [' '.join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "\n",
    "def compute_embeddings(texts, tokenizer, model):\n",
    "    \"\"\"\n",
    "    Computes embeddings for a list of texts using the given tokenizer and model.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(**inputs).last_hidden_state.mean(dim=1)\n",
    "    return embeddings\n",
    "\n",
    "def compute_cosine_similarity(embedding1, embedding2):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity between two embeddings.\n",
    "    \"\"\"\n",
    "    return torch.nn.functional.cosine_similarity(embedding1, embedding2).item()\n",
    "\n",
    "def tag_text(chunk, model_name):\n",
    "    \"\"\"\n",
    "    Generates tags for a given text chunk using the specified LLM model.\n",
    "    \"\"\"\n",
    "    response = ollama.chat(\n",
    "        model=model_name,\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "            You are a professional tagger. Your task is to analyze a given text and return 3 highly relevant tags to the main topics and themes of the text. \n",
    "\n",
    "            Guidelines:\n",
    "            1. Only provide the tags, nothing else.\n",
    "            2. Each tag must be a single word, not a phrase.\n",
    "            3. Separate the tags with commas, without spaces or additional formatting.\n",
    "\n",
    "            Example Input:\n",
    "            \"Artificial intelligence is transforming industries like healthcare, finance, and transportation.\"\n",
    "\n",
    "            Example Output:\n",
    "            ai,technology,automation\n",
    "\n",
    "            Now, generate tags for the following text:\n",
    "            \"{chunk}\"\n",
    "            \"\"\"\n",
    "        }]\n",
    "    )\n",
    "\n",
    "    # Extract and clean tags\n",
    "    if isinstance(response, list):\n",
    "        tags = [msg['content'] for msg in response if 'content' in msg]\n",
    "    elif isinstance(response, dict):\n",
    "        tags = response.get('message', {}).get('content', \"error,generating,tags\").split(',')\n",
    "    else:\n",
    "        tags = [\"error\", \"generating\", \"tags\"]\n",
    "\n",
    "    return [tag.strip() for tag in tags]\n",
    "\n",
    "def select_best_iteration(all_tags_per_iteration, avg_similarities_per_iteration):\n",
    "    \"\"\"\n",
    "    Selects the best iteration based on the highest average cosine similarity.\n",
    "    Returns the tags from the best iteration and its average similarity.\n",
    "    \"\"\"\n",
    "    # Find the iteration with the highest average similarity\n",
    "    best_iteration = max(avg_similarities_per_iteration, key=lambda x: x[1])[0]\n",
    "    \n",
    "    # Get the tags from the best iteration\n",
    "    best_iteration_tags = all_tags_per_iteration[best_iteration - 1]\n",
    "\n",
    "    return best_iteration_tags\n",
    "\n",
    "def process_file(file_path, model_name, output_folder, tokenizer, model, iterations=5):\n",
    "    \"\"\"\n",
    "    Processes a single file: splits it into chunks, tags each chunk, and saves results.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        original_text = f.read()\n",
    "\n",
    "    chunks = split_into_chunks(original_text)\n",
    "    all_tags_per_iteration = []  # To store tags per iteration\n",
    "    avg_similarities_per_iteration = []  # To store average similarity per iteration\n",
    "\n",
    "    for iteration in range(1, iterations + 1):\n",
    "        iteration_tags = []\n",
    "        iteration_similarities = []\n",
    "\n",
    "        for chunk in chunks:\n",
    "            tags = tag_text(chunk, model_name)\n",
    "            chunk_embedding = compute_embeddings([chunk], tokenizer, model)\n",
    "            tag_similarities = []\n",
    "\n",
    "            for tag in tags:\n",
    "                tag_embedding = compute_embeddings([tag], tokenizer, model)\n",
    "                similarity = compute_cosine_similarity(tag_embedding, chunk_embedding)\n",
    "                tag_similarities.append((tag, similarity))\n",
    "\n",
    "            iteration_tags.extend(tag_similarities)\n",
    "\n",
    "        # Sort tags by similarity\n",
    "        sorted_tags = sorted(iteration_tags, key=lambda x: x[1], reverse=True)\n",
    "        all_tags_per_iteration.append(sorted_tags)\n",
    "\n",
    "        # Save results to CSV for this iteration\n",
    "        csv_output_path = os.path.join(\n",
    "            output_folder,\n",
    "            f\"{os.path.basename(file_path).replace('.txt', '')}_tags_{iteration}.csv\"\n",
    "        )\n",
    "        save_tags_to_csv(csv_output_path, sorted_tags)\n",
    "\n",
    "        # Calculate average similarity for this iteration\n",
    "        avg_similarity = sum([similarity for _, similarity in iteration_tags]) / len(iteration_tags)\n",
    "        avg_similarities_per_iteration.append((iteration, avg_similarity))\n",
    "\n",
    "    # Use the select_best_iteration function to get the best tags\n",
    "    best_iteration_tags = select_best_iteration(all_tags_per_iteration, avg_similarities_per_iteration)\n",
    "\n",
    "    # Save the best tags to a CSV file\n",
    "    best_csv_output_path = os.path.join(\n",
    "        output_folder,\n",
    "        f\"{os.path.basename(file_path).replace('.txt', '')}_best_tags.csv\"\n",
    "    )\n",
    "    save_tags_to_csv(best_csv_output_path, best_iteration_tags)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_tags_to_csv(output_path, tags):\n",
    "    \"\"\"\n",
    "    Saves tags and their cosine similarities to a CSV file.\n",
    "    \"\"\"\n",
    "    with open(output_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(['tag_name', 'cosine_similarity'])\n",
    "        for tag, similarity in tags:\n",
    "            csv_writer.writerow([tag, f\"{similarity:.4f}\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b46de81-bdf2-4c57-809b-7268ebccb59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing files:   0%|                                                                                                                                                                                   | 0/97 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 28\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[27], line 24\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(file_path):\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m model_name, model_folder \u001b[38;5;129;01min\u001b[39;00m output_folders\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 24\u001b[0m             process_file(file_path, model_name, model_folder, tokenizer, model)\n\u001b[0;32m     25\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     26\u001b[0m pbar\u001b[38;5;241m.\u001b[39mclose()\n",
      "Cell \u001b[1;32mIn[24], line 154\u001b[0m, in \u001b[0;36mprocess_file\u001b[1;34m(file_path, model_name, output_folder, tokenizer, model, iterations)\u001b[0m\n\u001b[0;32m    151\u001b[0m iteration_similarities \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks:\n\u001b[1;32m--> 154\u001b[0m     tags \u001b[38;5;241m=\u001b[39m tag_text(chunk, model_name)\n\u001b[0;32m    155\u001b[0m     chunk_embedding \u001b[38;5;241m=\u001b[39m compute_embeddings([chunk], tokenizer, model)\n\u001b[0;32m    156\u001b[0m     tag_similarities \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[24], line 91\u001b[0m, in \u001b[0;36mtag_text\u001b[1;34m(chunk, model_name)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtag_text\u001b[39m(chunk, model_name):\n\u001b[0;32m     88\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;124;03m    Generates tags for a given text chunk using the specified LLM model.\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m     response \u001b[38;5;241m=\u001b[39m ollama\u001b[38;5;241m.\u001b[39mchat(\n\u001b[0;32m     92\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel_name,\n\u001b[0;32m     93\u001b[0m         messages\u001b[38;5;241m=\u001b[39m[{\n\u001b[0;32m     94\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     95\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124m            You are a professional tagger. Your task is to analyze a given text and return 3 highly relevant tags to the main topics and themes of the text. \u001b[39m\n\u001b[0;32m     97\u001b[0m \n\u001b[0;32m     98\u001b[0m \u001b[38;5;124m            Guidelines:\u001b[39m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124m            1. Only provide the tags, nothing else.\u001b[39m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124m            2. Each tag must be a single word, not a phrase.\u001b[39m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124m            3. Separate the tags with commas, without spaces or additional formatting.\u001b[39m\n\u001b[0;32m    102\u001b[0m \n\u001b[0;32m    103\u001b[0m \u001b[38;5;124m            Example Input:\u001b[39m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124m            \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArtificial intelligence is transforming industries like healthcare, finance, and transportation.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;124m            Example Output:\u001b[39m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;124m            ai,technology,automation\u001b[39m\n\u001b[0;32m    108\u001b[0m \n\u001b[0;32m    109\u001b[0m \u001b[38;5;124m            Now, generate tags for the following text:\u001b[39m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;124m            \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;124m            \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    112\u001b[0m         }]\n\u001b[0;32m    113\u001b[0m     )\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;66;03m# Extract and clean tags\u001b[39;00m\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mlist\u001b[39m):\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\od_zera_do_ai\\Lib\\site-packages\\ollama\\_client.py:236\u001b[0m, in \u001b[0;36mClient.chat\u001b[1;34m(self, model, messages, tools, stream, format, options, keep_alive)\u001b[0m\n\u001b[0;32m    233\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m images \u001b[38;5;241m:=\u001b[39m message\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    234\u001b[0m     message[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [_encode_image(image) \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images]\n\u001b[1;32m--> 236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_stream(\n\u001b[0;32m    237\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    238\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/api/chat\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    239\u001b[0m   json\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: model,\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m'\u001b[39m: messages,\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m'\u001b[39m: tools \u001b[38;5;129;01mor\u001b[39;00m [],\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m'\u001b[39m: stream,\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mformat\u001b[39m,\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptions\u001b[39m\u001b[38;5;124m'\u001b[39m: options \u001b[38;5;129;01mor\u001b[39;00m {},\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeep_alive\u001b[39m\u001b[38;5;124m'\u001b[39m: keep_alive,\n\u001b[0;32m    247\u001b[0m   },\n\u001b[0;32m    248\u001b[0m   stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    249\u001b[0m )\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\od_zera_do_ai\\Lib\\site-packages\\ollama\\_client.py:99\u001b[0m, in \u001b[0;36mClient._request_stream\u001b[1;34m(self, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_request_stream\u001b[39m(\n\u001b[0;32m     94\u001b[0m   \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     95\u001b[0m   \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m     96\u001b[0m   stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     97\u001b[0m   \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     98\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Mapping[\u001b[38;5;28mstr\u001b[39m, Any], Iterator[Mapping[\u001b[38;5;28mstr\u001b[39m, Any]]]:\n\u001b[1;32m---> 99\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\od_zera_do_ai\\Lib\\site-packages\\ollama\\_client.py:70\u001b[0m, in \u001b[0;36mClient._request\u001b[1;34m(self, method, url, **kwargs)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, method: \u001b[38;5;28mstr\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m httpx\u001b[38;5;241m.\u001b[39mResponse:\n\u001b[1;32m---> 70\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mrequest(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     72\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\od_zera_do_ai\\Lib\\site-packages\\httpx\\_client.py:837\u001b[0m, in \u001b[0;36mClient.request\u001b[1;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[0;32m    822\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[0;32m    824\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[0;32m    825\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    826\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    835\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[0;32m    836\u001b[0m )\n\u001b[1;32m--> 837\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(request, auth\u001b[38;5;241m=\u001b[39mauth, follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects)\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\od_zera_do_ai\\Lib\\site-packages\\httpx\\_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[0;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[0;32m    927\u001b[0m     request,\n\u001b[0;32m    928\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[0;32m    929\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m    930\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m    931\u001b[0m )\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\od_zera_do_ai\\Lib\\site-packages\\httpx\\_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[0;32m    955\u001b[0m         request,\n\u001b[0;32m    956\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m    957\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[0;32m    958\u001b[0m     )\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\od_zera_do_ai\\Lib\\site-packages\\httpx\\_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    989\u001b[0m     hook(request)\n\u001b[1;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\od_zera_do_ai\\Lib\\site-packages\\httpx\\_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1024\u001b[0m     )\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mhandle_request(request)\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\od_zera_do_ai\\Lib\\site-packages\\httpx\\_transports\\default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    234\u001b[0m )\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    245\u001b[0m )\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\od_zera_do_ai\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\od_zera_do_ai\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mhandle_request(\n\u001b[0;32m    197\u001b[0m         pool_request\u001b[38;5;241m.\u001b[39mrequest\n\u001b[0;32m    198\u001b[0m     )\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\od_zera_do_ai\\Lib\\site-packages\\httpcore\\_sync\\connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\od_zera_do_ai\\Lib\\site-packages\\httpcore\\_sync\\http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\od_zera_do_ai\\Lib\\site-packages\\httpcore\\_sync\\http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    107\u001b[0m     (\n\u001b[0;32m    108\u001b[0m         http_version,\n\u001b[0;32m    109\u001b[0m         status,\n\u001b[0;32m    110\u001b[0m         reason_phrase,\n\u001b[0;32m    111\u001b[0m         headers,\n\u001b[0;32m    112\u001b[0m         trailing_data,\n\u001b[1;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    115\u001b[0m         http_version,\n\u001b[0;32m    116\u001b[0m         status,\n\u001b[0;32m    117\u001b[0m         reason_phrase,\n\u001b[0;32m    118\u001b[0m         headers,\n\u001b[0;32m    119\u001b[0m     )\n\u001b[0;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\od_zera_do_ai\\Lib\\site-packages\\httpcore\\_sync\\http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_event(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\od_zera_do_ai\\Lib\\site-packages\\httpcore\\_sync\\http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mread(\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREAD_NUM_BYTES, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    226\u001b[0m     )\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\od_zera_do_ai\\Lib\\site-packages\\httpcore\\_backends\\sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv(max_bytes)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Initialize variables\n",
    "    input_file = 'D:\\\\Ai\\\\Audio-Classifier\\\\voiceapp\\\\lista-1.txt'\n",
    "    models_list = [        \n",
    "        'mistral:7b',\n",
    "        'mistral-small',\n",
    "         'llama3.2:3b',\n",
    "        'qwen2:7b',\n",
    "        'yi',\n",
    "        'glm4:9b',\n",
    "        'qwen2.5:7b',\n",
    "        'qwen2.5:72b'\n",
    "    ]\n",
    "    output_folders, tokenizer, model = initialize_environment(models_list)\n",
    "\n",
    "    # Read file paths\n",
    "    file_paths = read_file_paths(input_file)\n",
    "\n",
    "    # Process each file\n",
    "    pbar = tqdm(total=len(file_paths), desc=\"Processing files\")\n",
    "    for file_path in file_paths:\n",
    "        if os.path.exists(file_path):\n",
    "            for model_name, model_folder in output_folders.items():\n",
    "                process_file(file_path, model_name, model_folder, tokenizer, model)\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b6a32f-149f-4e94-8a45-93ad469a3dae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-conda-env-kernel",
   "language": "python",
   "name": "my-conda-env-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
